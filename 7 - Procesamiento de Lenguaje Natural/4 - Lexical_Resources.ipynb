{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dlLUY3dJ2TN4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('book')\n",
    "from nltk.book import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Los recursos lexicos son colecciones de palabras que contienen informacion sobre la palabra:\n",
    "# Ex: contexto de uso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1kPN1HL8jzDj"
   },
   "source": [
    "# Recursos léxicos (lexicons)\n",
    "\n",
    "*   Son colecciones de palabras o frases que tienen asociadas etiquetas o meta-informacion de algún tipo (POS tags, significados gramaticales, etc ...)\n",
    "\n",
    "**comentario:** POS (Part of Speech), también llamado etiquetado gramatical o etiquetado de palabras por categorias, consiste en etiquetar la categoria gramatical a la que pertence cada palabra en un volumen de texto, siendo las categorias: \n",
    "\n",
    "1.   Sustantivos\n",
    "2.   Adjetivos\n",
    "3.   Articulos\n",
    "4.   Pronombres\n",
    "5.   Verbos\n",
    "6.   Adverbios\n",
    "7.   Interjecciones\n",
    "8.   Preposiciones\n",
    "9.   Conjunciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4WrToBljd-t"
   },
   "outputs": [],
   "source": [
    "# Vocabularios: palabras únicas en un corpus\n",
    "vocab = sorted(set(text1))\n",
    "# Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1B_dvdADkV2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 18713, 'the': 13721, '.': 6862, 'of': 6536, 'and': 6024, 'a': 4569, 'to': 4542, ';': 4072, 'in': 3916, 'that': 2982, ...})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 18713, 'the': 13721, '.': 6862, 'of': 6536, 'and': 6024, 'a': 4569, 'to': 4542, ';': 4072, 'in': 3916, 'that': 2982, ...})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribuciones: frecuencia de aparición\n",
    "word_freq = FreqDist(text1)\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23901,
     "status": "ok",
     "timestamp": 1582724841381,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "I87FcXGDkitn",
    "outputId": "f4808d89-089e-4354-f087-293eee41fac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan', 'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría', 'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías', 'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean', 'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías', 'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan', 'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán', 'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía', 'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened']\n",
      "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan', 'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría', 'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías', 'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean', 'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías', 'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan', 'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán', 'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía', 'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened']\n"
     ]
    }
   ],
   "source": [
    "# Stopwords: Palabras muy usadas en el lenguaje que usualmente son filtradas en un pipeline de NLP (useless words)\n",
    "print(stopwords.words('spanish'))\n",
    "# Usualmente son conectores, o palabras MUY transformadas (Son poco relevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "taLQ6HevxKnY"
   },
   "source": [
    "## Fraccion de Stopwords en un corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24419,
     "status": "ok",
     "timestamp": 1582724842001,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "vL1nrH1VwbTz",
    "outputId": "089c4bb5-f96f-485a-b644-c2388c546d86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5862954769399469"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5862954769399469"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stopwords_percentage(text):\n",
    "  '''\n",
    "  aqui usamos un recurso léxico (stopwords) para filtrar un corpus\n",
    "  '''\n",
    "  stopwd = stopwords.words('english')\n",
    "  content = [w  for w in text if w.lower() not in stopwd]\n",
    "  return len(content)/len(text)\n",
    "\n",
    "stopwords_percentage(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SxEi53bIxrYZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a2hxgqJbyXdH"
   },
   "source": [
    "## Lexicons enriquecidos (listas comparativas de palabras)\n",
    "\n",
    "*   Construyendo diccionarios para traduccion de palabras en diferentes idiomas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24337,
     "status": "ok",
     "timestamp": 1582724842017,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "YeG2PcZeyaA4",
    "outputId": "a7854d26-67c3-440b-bc4a-4c903bead76d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', 'bg', 'bs', 'ca', 'cs', 'cu', 'de', 'en', 'es', 'fr', 'hr', 'it', 'la', 'mk', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sw', 'uk']\n",
      "['be', 'bg', 'bs', 'ca', 'cs', 'cu', 'de', 'en', 'es', 'fr', 'hr', 'it', 'la', 'mk', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sw', 'uk']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import swadesh\n",
    "#idiomas disponibles\n",
    "print(swadesh.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24239,
     "status": "ok",
     "timestamp": 1582724842019,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "TBXSl7NMz4UM",
    "outputId": "b0205583-9c01-4fe7-cf8e-995b8268e784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'you (singular), thou', 'he', 'we', 'you (plural)', 'they', 'this', 'that', 'here', 'there', 'who', 'what', 'where', 'when', 'how', 'not', 'all', 'many', 'some', 'few', 'other', 'one', 'two', 'three', 'four', 'five', 'big', 'long', 'wide', 'thick', 'heavy', 'small', 'short', 'narrow', 'thin', 'woman', 'man (adult male)', 'man (human being)', 'child', 'wife', 'husband', 'mother', 'father', 'animal', 'fish', 'bird', 'dog', 'louse', 'snake', 'worm', 'tree', 'forest', 'stick', 'fruit', 'seed', 'leaf', 'root', 'bark (from tree)', 'flower', 'grass', 'rope', 'skin', 'meat', 'blood', 'bone', 'fat (noun)', 'egg', 'horn', 'tail', 'feather', 'hair', 'head', 'ear', 'eye', 'nose', 'mouth', 'tooth', 'tongue', 'fingernail', 'foot', 'leg', 'knee', 'hand', 'wing', 'belly', 'guts', 'neck', 'back', 'breast', 'heart', 'liver', 'drink', 'eat', 'bite', 'suck', 'spit', 'vomit', 'blow', 'breathe', 'laugh', 'see', 'hear', 'know (a fact)', 'think', 'smell', 'fear', 'sleep', 'live', 'die', 'kill', 'fight', 'hunt', 'hit', 'cut', 'split', 'stab', 'scratch', 'dig', 'swim', 'fly (verb)', 'walk', 'come', 'lie', 'sit', 'stand', 'turn', 'fall', 'give', 'hold', 'squeeze', 'rub', 'wash', 'wipe', 'pull', 'push', 'throw', 'tie', 'sew', 'count', 'say', 'sing', 'play', 'float', 'flow', 'freeze', 'swell', 'sun', 'moon', 'star', 'water', 'rain', 'river', 'lake', 'sea', 'salt', 'stone', 'sand', 'dust', 'earth', 'cloud', 'fog', 'sky', 'wind', 'snow', 'ice', 'smoke', 'fire', 'ashes', 'burn', 'road', 'mountain', 'red', 'green', 'yellow', 'white', 'black', 'night', 'day', 'year', 'warm', 'cold', 'full', 'new', 'old', 'good', 'bad', 'rotten', 'dirty', 'straight', 'round', 'sharp', 'dull', 'smooth', 'wet', 'dry', 'correct', 'near', 'far', 'right', 'left', 'at', 'in', 'with', 'and', 'if', 'because', 'name']\n",
      "['I', 'you (singular), thou', 'he', 'we', 'you (plural)', 'they', 'this', 'that', 'here', 'there', 'who', 'what', 'where', 'when', 'how', 'not', 'all', 'many', 'some', 'few', 'other', 'one', 'two', 'three', 'four', 'five', 'big', 'long', 'wide', 'thick', 'heavy', 'small', 'short', 'narrow', 'thin', 'woman', 'man (adult male)', 'man (human being)', 'child', 'wife', 'husband', 'mother', 'father', 'animal', 'fish', 'bird', 'dog', 'louse', 'snake', 'worm', 'tree', 'forest', 'stick', 'fruit', 'seed', 'leaf', 'root', 'bark (from tree)', 'flower', 'grass', 'rope', 'skin', 'meat', 'blood', 'bone', 'fat (noun)', 'egg', 'horn', 'tail', 'feather', 'hair', 'head', 'ear', 'eye', 'nose', 'mouth', 'tooth', 'tongue', 'fingernail', 'foot', 'leg', 'knee', 'hand', 'wing', 'belly', 'guts', 'neck', 'back', 'breast', 'heart', 'liver', 'drink', 'eat', 'bite', 'suck', 'spit', 'vomit', 'blow', 'breathe', 'laugh', 'see', 'hear', 'know (a fact)', 'think', 'smell', 'fear', 'sleep', 'live', 'die', 'kill', 'fight', 'hunt', 'hit', 'cut', 'split', 'stab', 'scratch', 'dig', 'swim', 'fly (verb)', 'walk', 'come', 'lie', 'sit', 'stand', 'turn', 'fall', 'give', 'hold', 'squeeze', 'rub', 'wash', 'wipe', 'pull', 'push', 'throw', 'tie', 'sew', 'count', 'say', 'sing', 'play', 'float', 'flow', 'freeze', 'swell', 'sun', 'moon', 'star', 'water', 'rain', 'river', 'lake', 'sea', 'salt', 'stone', 'sand', 'dust', 'earth', 'cloud', 'fog', 'sky', 'wind', 'snow', 'ice', 'smoke', 'fire', 'ashes', 'burn', 'road', 'mountain', 'red', 'green', 'yellow', 'white', 'black', 'night', 'day', 'year', 'warm', 'cold', 'full', 'new', 'old', 'good', 'bad', 'rotten', 'dirty', 'straight', 'round', 'sharp', 'dull', 'smooth', 'wet', 'dry', 'correct', 'near', 'far', 'right', 'left', 'at', 'in', 'with', 'and', 'if', 'because', 'name']\n"
     ]
    }
   ],
   "source": [
    "print(swadesh.words('en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24178,
     "status": "ok",
     "timestamp": 1582724842033,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "MKoGBGVtz94p",
    "outputId": "c606479b-0be2-4ee6-cb02-c984f7f6ad2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('je', 'yo'), ('tu, vous', 'tú, usted'), ('il', 'él'), ('nous', 'nosotros'), ('vous', 'vosotros, ustedes'), ('ils, elles', 'ellos, ellas'), ('ceci', 'este'), ('cela', 'ese, aquel'), ('ici', 'aquí, acá'), ('là', 'ahí, allí, allá'), ('qui', 'quien'), ('quoi', 'que'), ('où', 'donde'), ('quand', 'cuando'), ('comment', 'como'), ('ne...pas', 'no'), ('tout', 'todo'), ('plusieurs', 'muchos'), ('quelques', 'algunos, unos'), ('peu', 'poco'), ('autre', 'otro'), ('un', 'uno'), ('deux', 'dos'), ('trois', 'tres'), ('quatre', 'cuatro'), ('cinq', 'cinco'), ('grand', 'grande'), ('long', 'largo'), ('large', 'ancho'), ('épais', 'gordo'), ('lourd', 'pesado'), ('petit', 'pequeño'), ('court', 'corto'), ('étroit', 'estrecho, angosto'), ('mince', 'delgado, flaco'), ('femme', 'mujer'), ('homme', 'hombre'), ('homme', 'hombre'), ('enfant', 'niño'), ('femme, épouse', 'esposa, mujer'), ('mari, époux', 'esposo, marido'), ('mère', 'madre'), ('père', 'padre'), ('animal', 'animal'), ('poisson', 'pez, pescado'), ('oiseau', 'ave, pájaro'), ('chien', 'perro'), ('pou', 'piojo'), ('serpent', 'serpiente, culebra'), ('ver', 'gusano'), ('arbre', 'árbol'), ('forêt', 'bosque'), ('bâton', 'palo'), ('fruit', 'fruta'), ('graine', 'semilla'), ('feuille', 'hoja'), ('racine', 'raíz'), ('écorce', 'corteza'), ('fleur', 'flor'), ('herbe', 'hierba, pasto'), ('corde', 'cuerda'), ('peau', 'piel'), ('viande', 'carne'), ('sang', 'sangre'), ('os', 'hueso'), ('graisse', 'grasa'), ('œuf', 'huevo'), ('corne', 'cuerno'), ('queue', 'cola'), ('plume', 'pluma'), ('cheveu', 'cabello, pelo'), ('tête', 'cabeza'), ('oreille', 'oreja'), ('œil', 'ojo'), ('nez', 'nariz'), ('bouche', 'boca'), ('dent', 'diente'), ('langue', 'lengua'), ('ongle', 'uña'), ('pied', 'pie'), ('jambe', 'pierna'), ('genou', 'rodilla'), ('main', 'mano'), ('aile', 'ala'), ('ventre', 'barriga, vientre, panza'), ('entrailles', 'entrañas, tripas'), ('cou', 'cuello'), ('dos', 'espalda'), ('sein, poitrine', 'pecho, seno'), ('cœur', 'corazón'), ('foie', 'hígado'), ('boire', 'beber, tomar'), ('manger', 'comer'), ('mordre', 'morder'), ('sucer', 'chupar'), ('cracher', 'escupir'), ('vomir', 'vomitar'), ('souffler', 'soplar'), ('respirer', 'respirar'), ('rire', 'reír'), ('voir', 'ver'), ('entendre', 'oír'), ('savoir', 'saber'), ('penser', 'pensar'), ('sentir', 'oler'), ('craindre, avoir peur', 'temer'), ('dormir', 'dormir'), ('vivre', 'vivir'), ('mourir', 'morir'), ('tuer', 'matar'), ('se battre', 'pelear'), ('chasser', 'cazar'), ('frapper', 'golpear'), ('couper', 'cortar'), ('fendre', 'partir'), ('poignarder', 'apuñalar'), ('gratter', 'arañar, rascar'), ('creuser', 'cavar'), ('nager', 'nadar'), ('voler', 'volar'), ('marcher', 'caminar'), ('venir', 'venir'), (\"s'étendre\", 'echarse, acostarse, tenderse'), (\"s'asseoir\", 'sentarse'), ('se lever', 'estar de pie'), ('tourner', 'voltear'), ('tomber', 'caer'), ('donner', 'dar'), ('tenir', 'sostener'), ('serrer', 'apretar'), ('frotter', 'frotar'), ('laver', 'lavar'), ('essuyer', 'limpiar'), ('tirer', 'tirar'), ('pousser', 'empujar'), ('jeter', 'tirar'), ('lier', 'atar'), ('coudre', 'coser'), ('compter', 'contar'), ('dire', 'decir'), ('chanter', 'cantar'), ('jouer', 'jugar'), ('flotter', 'flotar'), ('couler', 'fluir'), ('geler', 'helar'), ('gonfler', 'hincharse'), ('soleil', 'sol'), ('lune', 'luna'), ('étoile', 'estrella'), ('eau', 'agua'), ('pluie', 'lluvia'), ('rivière', 'río'), ('lac', 'lago'), ('mer', 'mar'), ('sel', 'sal'), ('pierre', 'piedra'), ('sable', 'arena'), ('poussière', 'polvo'), ('terre', 'tierra'), ('nuage', 'nube'), ('brouillard', 'niebla'), ('ciel', 'cielo'), ('vent', 'viento'), ('neige', 'nieve'), ('glace', 'hielo'), ('fumée', 'humo'), ('feu', 'fuego'), ('cendres', 'cenizas'), ('brûler', 'quemar'), ('route', 'camino'), ('montagne', 'montaña'), ('rouge', 'rojo'), ('vert', 'verde'), ('jaune', 'amarillo'), ('blanc', 'blanco'), ('noir', 'negro'), ('nuit', 'noche'), ('jour', 'día'), ('an, année', 'año'), ('chaud', 'cálido, tibio'), ('froid', 'frío'), ('plein', 'lleno'), ('nouveau', 'nuevo'), ('vieux', 'viejo'), ('bon', 'bueno'), ('mauvais', 'malo'), ('pourri', 'podrido'), ('sale', 'sucio'), ('droit', 'recto'), ('rond', 'redondo'), ('tranchant, pointu, aigu', 'afilado'), ('émoussé', 'desafilado'), ('lisse', 'suave, liso'), ('mouillé', 'mojado'), ('sec', 'seco'), ('juste, correct', 'correcto'), ('proche', 'cerca'), ('loin', 'lejos'), ('à droite', 'derecha'), ('à gauche', 'izquierda'), ('à', 'a, en, ante'), ('dans', 'en'), ('avec', 'con'), ('et', 'y'), ('si', 'si'), ('parce que', 'porque'), ('nom', 'nombre')]\n",
      "[('je', 'yo'), ('tu, vous', 'tú, usted'), ('il', 'él'), ('nous', 'nosotros'), ('vous', 'vosotros, ustedes'), ('ils, elles', 'ellos, ellas'), ('ceci', 'este'), ('cela', 'ese, aquel'), ('ici', 'aquí, acá'), ('là', 'ahí, allí, allá'), ('qui', 'quien'), ('quoi', 'que'), ('où', 'donde'), ('quand', 'cuando'), ('comment', 'como'), ('ne...pas', 'no'), ('tout', 'todo'), ('plusieurs', 'muchos'), ('quelques', 'algunos, unos'), ('peu', 'poco'), ('autre', 'otro'), ('un', 'uno'), ('deux', 'dos'), ('trois', 'tres'), ('quatre', 'cuatro'), ('cinq', 'cinco'), ('grand', 'grande'), ('long', 'largo'), ('large', 'ancho'), ('épais', 'gordo'), ('lourd', 'pesado'), ('petit', 'pequeño'), ('court', 'corto'), ('étroit', 'estrecho, angosto'), ('mince', 'delgado, flaco'), ('femme', 'mujer'), ('homme', 'hombre'), ('homme', 'hombre'), ('enfant', 'niño'), ('femme, épouse', 'esposa, mujer'), ('mari, époux', 'esposo, marido'), ('mère', 'madre'), ('père', 'padre'), ('animal', 'animal'), ('poisson', 'pez, pescado'), ('oiseau', 'ave, pájaro'), ('chien', 'perro'), ('pou', 'piojo'), ('serpent', 'serpiente, culebra'), ('ver', 'gusano'), ('arbre', 'árbol'), ('forêt', 'bosque'), ('bâton', 'palo'), ('fruit', 'fruta'), ('graine', 'semilla'), ('feuille', 'hoja'), ('racine', 'raíz'), ('écorce', 'corteza'), ('fleur', 'flor'), ('herbe', 'hierba, pasto'), ('corde', 'cuerda'), ('peau', 'piel'), ('viande', 'carne'), ('sang', 'sangre'), ('os', 'hueso'), ('graisse', 'grasa'), ('œuf', 'huevo'), ('corne', 'cuerno'), ('queue', 'cola'), ('plume', 'pluma'), ('cheveu', 'cabello, pelo'), ('tête', 'cabeza'), ('oreille', 'oreja'), ('œil', 'ojo'), ('nez', 'nariz'), ('bouche', 'boca'), ('dent', 'diente'), ('langue', 'lengua'), ('ongle', 'uña'), ('pied', 'pie'), ('jambe', 'pierna'), ('genou', 'rodilla'), ('main', 'mano'), ('aile', 'ala'), ('ventre', 'barriga, vientre, panza'), ('entrailles', 'entrañas, tripas'), ('cou', 'cuello'), ('dos', 'espalda'), ('sein, poitrine', 'pecho, seno'), ('cœur', 'corazón'), ('foie', 'hígado'), ('boire', 'beber, tomar'), ('manger', 'comer'), ('mordre', 'morder'), ('sucer', 'chupar'), ('cracher', 'escupir'), ('vomir', 'vomitar'), ('souffler', 'soplar'), ('respirer', 'respirar'), ('rire', 'reír'), ('voir', 'ver'), ('entendre', 'oír'), ('savoir', 'saber'), ('penser', 'pensar'), ('sentir', 'oler'), ('craindre, avoir peur', 'temer'), ('dormir', 'dormir'), ('vivre', 'vivir'), ('mourir', 'morir'), ('tuer', 'matar'), ('se battre', 'pelear'), ('chasser', 'cazar'), ('frapper', 'golpear'), ('couper', 'cortar'), ('fendre', 'partir'), ('poignarder', 'apuñalar'), ('gratter', 'arañar, rascar'), ('creuser', 'cavar'), ('nager', 'nadar'), ('voler', 'volar'), ('marcher', 'caminar'), ('venir', 'venir'), (\"s'étendre\", 'echarse, acostarse, tenderse'), (\"s'asseoir\", 'sentarse'), ('se lever', 'estar de pie'), ('tourner', 'voltear'), ('tomber', 'caer'), ('donner', 'dar'), ('tenir', 'sostener'), ('serrer', 'apretar'), ('frotter', 'frotar'), ('laver', 'lavar'), ('essuyer', 'limpiar'), ('tirer', 'tirar'), ('pousser', 'empujar'), ('jeter', 'tirar'), ('lier', 'atar'), ('coudre', 'coser'), ('compter', 'contar'), ('dire', 'decir'), ('chanter', 'cantar'), ('jouer', 'jugar'), ('flotter', 'flotar'), ('couler', 'fluir'), ('geler', 'helar'), ('gonfler', 'hincharse'), ('soleil', 'sol'), ('lune', 'luna'), ('étoile', 'estrella'), ('eau', 'agua'), ('pluie', 'lluvia'), ('rivière', 'río'), ('lac', 'lago'), ('mer', 'mar'), ('sel', 'sal'), ('pierre', 'piedra'), ('sable', 'arena'), ('poussière', 'polvo'), ('terre', 'tierra'), ('nuage', 'nube'), ('brouillard', 'niebla'), ('ciel', 'cielo'), ('vent', 'viento'), ('neige', 'nieve'), ('glace', 'hielo'), ('fumée', 'humo'), ('feu', 'fuego'), ('cendres', 'cenizas'), ('brûler', 'quemar'), ('route', 'camino'), ('montagne', 'montaña'), ('rouge', 'rojo'), ('vert', 'verde'), ('jaune', 'amarillo'), ('blanc', 'blanco'), ('noir', 'negro'), ('nuit', 'noche'), ('jour', 'día'), ('an, année', 'año'), ('chaud', 'cálido, tibio'), ('froid', 'frío'), ('plein', 'lleno'), ('nouveau', 'nuevo'), ('vieux', 'viejo'), ('bon', 'bueno'), ('mauvais', 'malo'), ('pourri', 'podrido'), ('sale', 'sucio'), ('droit', 'recto'), ('rond', 'redondo'), ('tranchant, pointu, aigu', 'afilado'), ('émoussé', 'desafilado'), ('lisse', 'suave, liso'), ('mouillé', 'mojado'), ('sec', 'seco'), ('juste, correct', 'correcto'), ('proche', 'cerca'), ('loin', 'lejos'), ('à droite', 'derecha'), ('à gauche', 'izquierda'), ('à', 'a, en, ante'), ('dans', 'en'), ('avec', 'con'), ('et', 'y'), ('si', 'si'), ('parce que', 'porque'), ('nom', 'nombre')]\n"
     ]
    }
   ],
   "source": [
    "fr2es = swadesh.entries(['fr', 'es'])\n",
    "print(fr2es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24093,
     "status": "ok",
     "timestamp": 1582724842040,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "zFrKBsN80TBs",
    "outputId": "3b8cc5bd-db44-4c29-f8ac-9a0b2020b136"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'perro'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'perro'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate = dict(fr2es)\n",
    "translate['chien']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23956,
     "status": "ok",
     "timestamp": 1582724842051,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "7ZZoGqpJ1JYx",
    "outputId": "accbc583-b051-4d5b-ae66-79755161031d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tirar'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'tirar'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate['jeter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "blP4PK213IgP"
   },
   "source": [
    "# WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HaIV6smBUo1a"
   },
   "source": [
    "## Referencias \n",
    "\n",
    "* [WordNet Lecture](https://sp1718.github.io/wordnet_lecture.pdf)\n",
    "* [What is WordNet?](https://wordnet.princeton.edu)\n",
    "* [WordNet Interface NLTK](http://www.nltk.org/howto/wordnet.html)\n",
    "* [LAS-WordNet](https://www.datos.gov.co/Ciencia-Tecnolog-a-e-Innovaci-n/LAS-WordNet-una-WordNet-para-el-espa-ol-obtenida-c/8z8d-85m7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24464,
     "status": "ok",
     "timestamp": 1582724842635,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "6E1VfuY11Lce",
    "outputId": "6e3b5c38-d051-40f9-9830-9118a36e51fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw to\n",
      "[nltk_data]     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n",
      "[nltk_data] Downloading package omw to\n",
      "[nltk_data]     C:\\Users\\Tarto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('omw')\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26388,
     "status": "ok",
     "timestamp": 1582724844650,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "tAKiyUOY3NVz",
    "outputId": "d470b120-25cb-42b8-df1e-9fd80c7cd48d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01'),\n",
       " Synset('carriage.n.04'),\n",
       " Synset('carrier.n.02'),\n",
       " Synset('cart.n.01'),\n",
       " Synset('chariot.n.02'),\n",
       " Synset('cartload.n.01')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01'),\n",
       " Synset('carriage.n.04'),\n",
       " Synset('carrier.n.02'),\n",
       " Synset('cart.n.01'),\n",
       " Synset('chariot.n.02'),\n",
       " Synset('cartload.n.01')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# synset: grupo de sinómimos de una palabra.\n",
    "ss = wn.synsets('carro', lang='spa')\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26300,
     "status": "ok",
     "timestamp": 1582724844653,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "Vl0HpwlX4hge",
    "outputId": "f5d30d82-fc02-41ed-f805-625eeed08015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car.n.01 :  a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      " *  car\n",
      " *  auto\n",
      " *  automobile\n",
      " *  machine\n",
      " *  motorcar\n",
      "carriage.n.04 :  a machine part that carries something else\n",
      " *  carriage\n",
      "carrier.n.02 :  a self-propelled wheeled vehicle designed specifically to carry something\n",
      " *  carrier\n",
      "cart.n.01 :  a heavy open wagon usually having two wheels and drawn by an animal\n",
      " *  cart\n",
      "chariot.n.02 :  a two-wheeled horse-drawn battle vehicle; used in war and races in ancient Egypt and Greece and Rome\n",
      " *  chariot\n",
      "cartload.n.01 :  the quantity that a cart holds\n",
      " *  cartload\n",
      "car.n.01 :  a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      " *  car\n",
      " *  auto\n",
      " *  automobile\n",
      " *  machine\n",
      " *  motorcar\n",
      "carriage.n.04 :  a machine part that carries something else\n",
      " *  carriage\n",
      "carrier.n.02 :  a self-propelled wheeled vehicle designed specifically to carry something\n",
      " *  carrier\n",
      "cart.n.01 :  a heavy open wagon usually having two wheels and drawn by an animal\n",
      " *  cart\n",
      "chariot.n.02 :  a two-wheeled horse-drawn battle vehicle; used in war and races in ancient Egypt and Greece and Rome\n",
      " *  chariot\n",
      "cartload.n.01 :  the quantity that a cart holds\n",
      " *  cartload\n"
     ]
    }
   ],
   "source": [
    "# explorando los synsets\n",
    "for syn in ss:\n",
    "  print(syn.name(), ': ', syn.definition())\n",
    "  for name in syn.lemma_names():\n",
    "    print(' * ', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SB2daMz_QI9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a91d02bf45a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# * http://dlacombejr.github.io/programming/2015/09/28/visualizing-cifar-10-categories-with-wordnet-and-networkx.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a91d02bf45a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# * http://dlacombejr.github.io/programming/2015/09/28/visualizing-cifar-10-categories-with-wordnet-and-networkx.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "# visualization references\n",
    "# * http://www.randomhacks.net/2009/12/29/visualizing-wordnet-relationships-as-graphs/\n",
    "# * http://dlacombejr.github.io/programming/2015/09/28/visualizing-cifar-10-categories-with-wordnet-and-networkx.html\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def closure_graph(synset, fn):\n",
    "    seen = set()\n",
    "    graph = nx.DiGraph()\n",
    "    labels = {}\n",
    "\n",
    "    def recurse(s):\n",
    "        if not s in seen:\n",
    "            seen.add(s)\n",
    "            labels[s.name] = s.name().split('.')[0]\n",
    "            graph.add_node(s.name)\n",
    "            for s1 in fn(s):\n",
    "                graph.add_node(s1.name)\n",
    "                graph.add_edge(s.name, s1.name)\n",
    "                recurse(s1)\n",
    "\n",
    "    recurse(synset)\n",
    "    return graph, labels\n",
    "\n",
    "def draw_text_graph(G, labels):\n",
    "    plt.figure(figsize=(18,12))\n",
    "    pos = nx.planar_layout(G, scale=18)\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=\"red\", linewidths=0, node_size=500)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=20, labels=labels)\n",
    "    nx.draw_networkx_edges(G, pos)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a0a4e467a61c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclousure_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mseen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a0a4e467a61c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclousure_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mseen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def clousure_graph(synset, fn):\n",
    "  seen = set()\n",
    "  graph = nx.DiGraph()\n",
    "  labels = {}\n",
    "\n",
    "  def recurse(s):\n",
    "    if not s in seen:\n",
    "      seen.add(s)\n",
    "      labels[s.name] = s.name().split('.')[0]\n",
    "      graph.add_node(s.name)\n",
    "      for s1 in fn(s):\n",
    "        graph.add_node(s1.name)\n",
    "        graph.add_edge(s.name, s1.name)\n",
    "        recurse(s1)\n",
    "  recurse(synset)\n",
    "  return graph, labels\n",
    "\n",
    "def draw_text_graph(G, labels):\n",
    "  plt.figure(figsize=(18, 12))\n",
    "  pos = nx.planar_layout(G, scale=18)\n",
    "  nx.draw_networkx_nodes(G, pos, node_color=\"red\", linewidths=0, node_size=500)\n",
    "  nx.draw_networkx_labels(G, pos, font_size=20, labels=labels)\n",
    "  nx.draw_networkx_edges(G, pos)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4cNMOXyMAXQ"
   },
   "source": [
    "## **Hyponyms:** Conceptos que son más especificos que la palabra raiz de la cual derivan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 754
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28179,
     "status": "ok",
     "timestamp": 1582724846688,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "cgpNclQqHTzY",
    "outputId": "a986ccb4-24da-4b96-de16-b787e103d47f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car.n.01\n",
      "car.n.01\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'closure_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-7035b42f0b66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyponyms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdraw_text_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'closure_graph' is not defined"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'closure_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-7035b42f0b66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyponyms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdraw_text_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'closure_graph' is not defined"
     ]
    }
   ],
   "source": [
    "print(ss[0].name())\n",
    "G, labels = closure_graph(ss[0], fn = lambda s: s.hyponyms())\n",
    "draw_text_graph(G, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XDVJV5UoMMKs"
   },
   "source": [
    "## **Hypernyms**: conceptos que son mas generales !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 754
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28127,
     "status": "ok",
     "timestamp": 1582724846691,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "XrywI6b-Hi3Y",
    "outputId": "d3b0eacc-e6b4-4df6-e008-94a7779d7926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car.n.01\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'closure_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ace5c387cec5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypernyms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdraw_text_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'closure_graph' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car.n.01\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'closure_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ace5c387cec5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypernyms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdraw_text_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'closure_graph' is not defined"
     ]
    }
   ],
   "source": [
    "print(ss[0].name())\n",
    "G, labels = closure_graph(ss[0], fn = lambda s: s.hypernyms())\n",
    "draw_text_graph(G, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G2qP9jdgM1hn"
   },
   "source": [
    "## Similitud Semántica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JOVw0Lf5Mgyv"
   },
   "outputs": [],
   "source": [
    "def show_syns(word):\n",
    "  ss = wn.synsets(word, lang='spa')\n",
    "  for syn in ss:\n",
    "    print(syn.name(), ': ', syn.definition())\n",
    "    for name in syn.lemma_names():\n",
    "      print(' * ', name)\n",
    "  return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28367,
     "status": "ok",
     "timestamp": 1582724847033,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "bzT0cnxJQT5y",
    "outputId": "59568900-2bd0-456f-b281-cfa8b2990fdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog.n.01 :  a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      " *  dog\n",
      " *  domestic_dog\n",
      " *  Canis_familiaris\n",
      "rotter.n.01 :  a person who is deemed to be despicable or contemptible\n",
      " *  rotter\n",
      " *  dirty_dog\n",
      " *  rat\n",
      " *  skunk\n",
      " *  stinker\n",
      " *  stinkpot\n",
      " *  bum\n",
      " *  puke\n",
      " *  crumb\n",
      " *  lowlife\n",
      " *  scum_bag\n",
      " *  so-and-so\n",
      " *  git\n",
      "dog.n.01 :  a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      " *  dog\n",
      " *  domestic_dog\n",
      " *  Canis_familiaris\n",
      "rotter.n.01 :  a person who is deemed to be despicable or contemptible\n",
      " *  rotter\n",
      " *  dirty_dog\n",
      " *  rat\n",
      " *  skunk\n",
      " *  stinker\n",
      " *  stinkpot\n",
      " *  bum\n",
      " *  puke\n",
      " *  crumb\n",
      " *  lowlife\n",
      " *  scum_bag\n",
      " *  so-and-so\n",
      " *  git\n"
     ]
    }
   ],
   "source": [
    "ss = show_syns('perro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28273,
     "status": "ok",
     "timestamp": 1582724847039,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "LV6ByntzQreJ",
    "outputId": "9df94578-cded-4940-c027-0970d58a3f45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat.n.01 :  feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n",
      " *  cat\n",
      " *  true_cat\n",
      "tom.n.02 :  male cat\n",
      " *  tom\n",
      " *  tomcat\n",
      "dodger.n.01 :  a shifty deceptive person\n",
      " *  dodger\n",
      " *  fox\n",
      " *  slyboots\n",
      "cat.n.01 :  feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n",
      " *  cat\n",
      " *  true_cat\n",
      "tom.n.02 :  male cat\n",
      " *  tom\n",
      " *  tomcat\n",
      "dodger.n.01 :  a shifty deceptive person\n",
      " *  dodger\n",
      " *  fox\n",
      " *  slyboots\n"
     ]
    }
   ],
   "source": [
    "ss2 = show_syns('gato')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28207,
     "status": "ok",
     "timestamp": 1582724847044,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "2DoHzNxHRfpK",
    "outputId": "f48c21aa-f3a4-4cf3-f20c-84e37862e329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animal.n.01 :  a living organism characterized by voluntary movement\n",
      " *  animal\n",
      " *  animate_being\n",
      " *  beast\n",
      " *  brute\n",
      " *  creature\n",
      " *  fauna\n",
      "beast.n.02 :  a cruelly rapacious person\n",
      " *  beast\n",
      " *  wolf\n",
      " *  savage\n",
      " *  brute\n",
      " *  wildcat\n",
      "dunce.n.01 :  a stupid person; these words are used to express a low opinion of someone's intelligence\n",
      " *  dunce\n",
      " *  dunderhead\n",
      " *  numskull\n",
      " *  blockhead\n",
      " *  bonehead\n",
      " *  lunkhead\n",
      " *  hammerhead\n",
      " *  knucklehead\n",
      " *  loggerhead\n",
      " *  muttonhead\n",
      " *  shithead\n",
      " *  dumbass\n",
      " *  fuckhead\n",
      "animal.n.01 :  a living organism characterized by voluntary movement\n",
      " *  animal\n",
      " *  animate_being\n",
      " *  beast\n",
      " *  brute\n",
      " *  creature\n",
      " *  fauna\n",
      "beast.n.02 :  a cruelly rapacious person\n",
      " *  beast\n",
      " *  wolf\n",
      " *  savage\n",
      " *  brute\n",
      " *  wildcat\n",
      "dunce.n.01 :  a stupid person; these words are used to express a low opinion of someone's intelligence\n",
      " *  dunce\n",
      " *  dunderhead\n",
      " *  numskull\n",
      " *  blockhead\n",
      " *  bonehead\n",
      " *  lunkhead\n",
      " *  hammerhead\n",
      " *  knucklehead\n",
      " *  loggerhead\n",
      " *  muttonhead\n",
      " *  shithead\n",
      " *  dumbass\n",
      " *  fuckhead\n"
     ]
    }
   ],
   "source": [
    "ss3 = show_syns('animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5T1T9eLkQtx4"
   },
   "outputs": [],
   "source": [
    "# En todos los casos se usara el 1er significado, para utilizar ese contexto\n",
    "\n",
    "perro = ss[0]\n",
    "gato = ss2[0]\n",
    "animal = ss3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28115,
     "status": "ok",
     "timestamp": 1582724847047,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "7iS-e7cKRnqk",
    "outputId": "870e4241-14d4-4d80-b991-99f06540c7d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similitud entre 'animal' y 'perro'\n",
    "animal.path_similarity(perro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28053,
     "status": "ok",
     "timestamp": 1582724847051,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "2ROB6Dm7RrS1",
    "outputId": "bd09f120-53f6-492b-97af-ec11cb44c490"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similitud entre 'animal' y 'gato'\n",
    "animal.path_similarity(gato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27991,
     "status": "ok",
     "timestamp": 1582724847052,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "5peF3kqGSBys",
    "outputId": "48cff834-efee-44e0-88bd-87fae4e5b31b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perro.path_similarity(gato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27928,
     "status": "ok",
     "timestamp": 1582724847056,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "V6-BLiSPSFEA",
    "outputId": "960bc4f5-e4e2-434e-bd06-c36c1b4b7d4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perro.path_similarity(perro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rC5pwpNkUw8D"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-e727ba469cb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshortest_path_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-e727ba469cb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshortest_path_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "def traverse(graph, start, node):\n",
    "  graph.depth[node.name] = node.shortest_path_distance(start)\n",
    "  for child in node.hyponyms():\n",
    "    graph.add_edge(node.name, child.name)\n",
    "    traverse(graph, start, child)\n",
    "\n",
    "def hyponym_graph(start):\n",
    "  G = nx.Graph()\n",
    "  G.depth = {}\n",
    "  traverse(G, start, start)\n",
    "  return G\n",
    "\n",
    "def graph_draw(graph):\n",
    "  nx.draw_graphviz(graph, \n",
    "                   node_size = [16*graph.degree(n) for n in graph], \n",
    "                   node_color = [graph.depth[n] for n in graph], \n",
    "                   with_labels = True)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 423,
     "status": "error",
     "timestamp": 1582725209492,
     "user": {
      "displayName": "Francisco Camacho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUaNNj72-A-ZLpzeOCw1kooH47L4wGZaSy6fUG=s64",
      "userId": "03320326049189164988"
     },
     "user_tz": 300
    },
    "id": "WUVAejkOxTdb",
    "outputId": "b92e7f72-3107-416a-8c24-a8d4a7dbb61b"
   },
   "outputs": [],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "graph = hyponym_graph(dog)\n",
    "graph_draw(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ZSpVuemxcOr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOV3/KuEED7D513TqGOgh5j",
   "name": "[C6]_Lexical_Resources.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
